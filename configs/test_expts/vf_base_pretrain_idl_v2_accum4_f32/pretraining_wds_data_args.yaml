dataset_root_dir: s3://fm-a-star-data/pre-training
training_dataset: idl/idl-{00000..01308}.tar #::c4/{00000000..00001024}.tar
validation_dataset: idl/idl-01309.tar
region: us-west-2  # us-east-1
eval_ds_length: 20 # (actually its X * num_dl_processes * eval_batch_size_per_device)
task: donut_pretrain # docvqa
num_workers: 8
image_size: [ 1536, 768 ]
image_patch_size: 64
max_seq_length: 1480
smart_order: false
num_samples: null
add_space_to_word: true
use_separator: true
use_image: true
add_question: false # true
s3_handler: false  # true

# pretraining regime
pretraining_task: LearnToRead # SuffixPred # T5MLM or SuffixPred
mean_noise_span_length: 4 # average length of the span
labels_as_full_text: false # if to predict the ocr as is and not the ids and corresponding span
template: null # template to use for the llm span mask identifier or otherwise known as sentinal ids (T5 uses <extra_id_1>) null uses numbers
